{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6699af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931b0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data already in keras. \n",
    "#ELse data can be get at Yann Lecun website: http://yann.lecun.com/exdb/mnist/ (\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb00c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.         0.         0.55294118 1.         0.66666667 0.11372549 0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#@title Double-click to see a solution to Task 1. \n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0\n",
    "print(x_train_normalized[2900][10]) # Output a normalized row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d225cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function\n",
    "def plot_curve(title,epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "  plt.title(title)\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6c2a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def create_model(my_learning_rate):\\n    c#reate and compile a deep neural net.\\n    model = tf.keras.models.Sequential()\\n\\n    # The features are stored in a two-dimensional 28X28 array. \\n    # Flatten that two-dimensional array into a one-dimensional \\n    # 784-element array.\\n    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\\n\\n    # Define the first hidden layer.   \\n    model.add(tf.keras.layers.Dense(units=32, activation=\\'relu\\'))\\n\\n    # Define a dropout regularization layer. \\n    model.add(tf.keras.layers.Dropout(rate=0.2))\\n\\n    # Define the output layer. It had 10 units because we have 10 classes\\n    model.add(tf.keras.layers.Dense(units=10, activation=\\'softmax\\'))     \\n\\n    # compile the model to use it. We use Adam as optimizer and sparse_categorical_crossentropy because\\n    # we have a multi-class classification\\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\\n                loss=\"sparse_categorical_crossentropy\",\\n                metrics=[\\'accuracy\\'])\\n\\n    return model     '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def create_model(my_learning_rate):\n",
    "    c#reate and compile a deep neural net.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # The features are stored in a two-dimensional 28X28 array. \n",
    "    # Flatten that two-dimensional array into a one-dimensional \n",
    "    # 784-element array.\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Define the first hidden layer.   \n",
    "    model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "    # Define a dropout regularization layer. \n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Define the output layer. It had 10 units because we have 10 classes\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "\n",
    "    # compile the model to use it. We use Adam as optimizer and sparse_categorical_crossentropy because\n",
    "    # we have a multi-class classification\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4062f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer={\"SGD\" : lambda  l: tf.keras.optimizers.SGD(learning_rate=l),\n",
    "\"RMSprop\" : lambda  l: tf.keras.optimizers.RMSprop(learning_rate=l),\n",
    "\"Adam\" : lambda  l: tf.keras.optimizers.Adam(learning_rate=l),\n",
    "\"AdamW\" : lambda  l: tf.keras.optimizers.AdamW(learning_rate=l),\n",
    "\"Adadelta\" : lambda  l: tf.keras.optimizers.Adadelta(learning_rate=l),\n",
    "\"Adagrad\" : lambda  l: tf.keras.optimizers.Adagrad(learning_rate=l),\n",
    "\"Adamax\" : lambda  l: tf.keras.optimizers.Adamax(learning_rate=l),\n",
    "\"Adafactor\" : lambda  l: tf.keras.optimizers.Adafactor(learning_rate=l),\n",
    "\"Nadam\" : lambda  l: tf.keras.optimizers.Nadam(learning_rate=l),\n",
    "\"Ftrl\" : lambda  l: tf.keras.optimizers.Ftrl(learning_rate=l)}\n",
    "\n",
    "def create_optimizer(name, learning_rate):\n",
    "    return d_optimizer.get(name)(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f08de64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(k, dict_layer,model):\n",
    "    param = dict_layer.get(k)\n",
    "    model.add(tf.keras.layers.Dense(units=param.get(\"nb_node\"), activation=param.get(\"activation\")))\n",
    "    # Define a dropout regularization layer. \n",
    "    model.add(tf.keras.layers.Dropout(rate=param.get(\"drop_out_rate\")))\n",
    "    return model\n",
    "\n",
    "def create_model(dict_layer:dict, optimizer:str, loss:str, learning_rate, metrics:list):\n",
    "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "    \"\"\"key of dict_layer must be in the form {1 : {param1}, 2 : {param1} \n",
    "        with 1 being layer 1, 2 being layer 2, etc. param has the key values\n",
    "        \"activation\" : \"activation_function_name\"\n",
    "        \"nb_node\" : nb_node\n",
    "        \"drop_out_rate\" : drop_out_rate_value (not use for the last layer)  \"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    # The features are stored in a two-dimensional 28X28 array. \n",
    "    # Flatten that two-dimensional array into a one-dimensional \n",
    "    # 784-element array.\n",
    "    print(list(dict_layer))\n",
    "    for k in range(1,len(dict_layer)):\n",
    "        model=create_layer(k,dict_layer,model)\n",
    "    param=dict_layer.get(len(dict_layer))\n",
    "    # Define the output layer. It had 10 units because we have 10 classes\n",
    "    model.add(tf.keras.layers.Dense(param.get(\"nb_node\"), activation=param.get(\"activation\")))     \n",
    "\n",
    "    # compile the model to use it. We use Adam as optimizer and sparse_categorical_crossentropy because\n",
    "    # we have a multi-class classification\n",
    "    model.compile(optimizer=create_optimizer(optimizer,learning_rate=learning_rate),\n",
    "                    loss=loss,\n",
    "                    metrics=metrics)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71daff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1, verbose=2):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split, verbose = verbose)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return model, epochs, hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7f6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dict_layer, optimizer, loss, learning_rate, metrics,\n",
    "                   epochs, batch_size, validation_split, verbose):\n",
    "    my_model = create_model(dict_layer = layers, \n",
    "                            optimizer = \"Adam\",\n",
    "                            loss=\"sparse_categorical_crossentropy\",\n",
    "                            learning_rate=learning_rate,\n",
    "                            metrics=['accuracy'])\n",
    "    # Train the model on the normalized training set.\n",
    "    print(list(my_model.layers))\n",
    "    my_model, epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
    "                               epochs, batch_size, validation_split, verbose = 0)\n",
    "\n",
    "    # Plot a graph of the metric vs. epochs.\n",
    "    title = \"\"\n",
    "    for v in dict_layer.values():\n",
    "        title += v.get(\"activation\") + \" + \"\n",
    "    title=title[:-2]\n",
    "    list_of_metrics_to_plot = ['accuracy']\n",
    "    print(\"------------ \",title,\" ------------\" )\n",
    "    plot_curve(title,epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "    # Evaluate against the test set.\n",
    "    print(\"\\n Evaluate the new model against the test set:\")\n",
    "    my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a863789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[<keras.layers.reshaping.flatten.Flatten object at 0x0000019ABFF37970>, <keras.layers.core.dense.Dense object at 0x0000019ABFF99040>, <keras.layers.regularization.dropout.Dropout object at 0x0000019ABFFA5E50>, <keras.layers.core.dense.Dense object at 0x0000019ABFFBBEB0>, <keras.layers.regularization.dropout.Dropout object at 0x0000019ABFFBF520>, <keras.layers.core.dense.Dense object at 0x0000019ABFFBF220>]\n",
      "------------  relu   ------------\n",
      "\n",
      " Evaluate the new model against the test set:\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9829\n",
      "[1, 2, 3]\n",
      "[<keras.layers.reshaping.flatten.Flatten object at 0x0000019ABFFD1D00>, <keras.layers.core.dense.Dense object at 0x0000019AC0568AC0>, <keras.layers.regularization.dropout.Dropout object at 0x0000019AC0568CD0>, <keras.layers.core.dense.Dense object at 0x0000019AC056CBE0>, <keras.layers.regularization.dropout.Dropout object at 0x0000019AC0569850>, <keras.layers.core.dense.Dense object at 0x0000019AC056C8E0>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m arch \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m1\u001b[39m:layer_1_relu},{\u001b[38;5;241m1\u001b[39m:layer_1,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_2,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_1,\u001b[38;5;241m2\u001b[39m:layer_2, \u001b[38;5;241m3\u001b[39m:layer_3}]    \n\u001b[0;32m     24\u001b[0m traintest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m dc : test_model(dict_layer \u001b[38;5;241m=\u001b[39m dc, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m                                 loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m                                 learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     27\u001b[0m                                 epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size \u001b[38;5;241m=\u001b[39m batch_size, \n\u001b[0;32m     28\u001b[0m                                 validation_split \u001b[38;5;241m=\u001b[39m validation_split,verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m [traintest(dc) \u001b[38;5;28;01mfor\u001b[39;00m dc \u001b[38;5;129;01min\u001b[39;00m arch]\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m arch \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m1\u001b[39m:layer_1_relu},{\u001b[38;5;241m1\u001b[39m:layer_1,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_2,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_1,\u001b[38;5;241m2\u001b[39m:layer_2, \u001b[38;5;241m3\u001b[39m:layer_3}]    \n\u001b[0;32m     24\u001b[0m traintest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m dc : test_model(dict_layer \u001b[38;5;241m=\u001b[39m dc, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m                                 loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m                                 learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     27\u001b[0m                                 epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size \u001b[38;5;241m=\u001b[39m batch_size, \n\u001b[0;32m     28\u001b[0m                                 validation_split \u001b[38;5;241m=\u001b[39m validation_split,verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m [\u001b[43mtraintest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dc \u001b[38;5;129;01min\u001b[39;00m arch]\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(dc)\u001b[0m\n\u001b[0;32m     21\u001b[0m  \u001b[38;5;66;03m#(dict_layer,optimizer:str, loss:str, learning_rate, metrics:list)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m arch \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m1\u001b[39m:layer_1_relu},{\u001b[38;5;241m1\u001b[39m:layer_1,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_2,\u001b[38;5;241m2\u001b[39m:layer_3},{\u001b[38;5;241m1\u001b[39m : layer_1,\u001b[38;5;241m2\u001b[39m:layer_2, \u001b[38;5;241m3\u001b[39m:layer_3}]    \n\u001b[1;32m---> 24\u001b[0m traintest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m dc : \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msparse_categorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m [traintest(dc) \u001b[38;5;28;01mfor\u001b[39;00m dc \u001b[38;5;129;01min\u001b[39;00m arch]\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(dict_layer, optimizer, loss, learning_rate, metrics, epochs, batch_size, validation_split, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model on the normalized training set.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(my_model\u001b[38;5;241m.\u001b[39mlayers))\n\u001b[1;32m---> 10\u001b[0m my_model, epochs, hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Plot a graph of the metric vs. epochs.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_features, train_label, epochs, batch_size, validation_split, verbose)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, train_features, train_label, epochs,\n\u001b[0;32m      2\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124;03m\"\"\"Train the model by feeding it data.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m   history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;66;03m# To track the progression of training, gather a snapshot\u001b[39;00m\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;66;03m# of the model's metrics at each epoch. \u001b[39;00m\n\u001b[0;32m     11\u001b[0m   epochs \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mepoch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 1000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "#my_model = create_model(learning_rate)\n",
    "layer_1_relu = {\"activation\" : \"relu\",\n",
    "           \"nb_node\" : 10,\n",
    "           \"drop_out_rate\" : 0.2}   \n",
    "layer_1 = {\"activation\" : \"relu\",\n",
    "           \"nb_node\" : 392,\n",
    "           \"drop_out_rate\" : 0.2}    \n",
    "layer_2 = {\"activation\" : \"swish\",\n",
    "           \"nb_node\" : 98,\n",
    "           \"drop_out_rate\" : 0.2}    \n",
    "layer_3 = {\"activation\" : \"softmax\",\n",
    "           \"nb_node\" : 10}    \n",
    "layers= {1 : layer_1,2:layer_2, 3:layer_3}\n",
    " #(dict_layer,optimizer:str, loss:str, learning_rate, metrics:list)\n",
    "arch = [{1:layer_1_relu},{1:layer_1,2:layer_3},{1 : layer_2,2:layer_3},{1 : layer_1,2:layer_2, 3:layer_3}]    \n",
    "\n",
    "traintest = lambda dc : test_model(dict_layer = dc, optimizer = \"Adam\",\n",
    "                                loss=\"sparse_categorical_crossentropy\",\n",
    "                                learning_rate=learning_rate,metrics=['accuracy'],\n",
    "                                epochs=epochs, batch_size = batch_size, \n",
    "                                validation_split = validation_split,verbose = 0)\n",
    "[traintest(dc) for dc in arch]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aabb97",
   "metadata": {},
   "source": [
    "Relu alone is sufficient to have a good accuracy. But comratively to other architecture with only one layer it has many more nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
